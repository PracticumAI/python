{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)  <img src='https://github.com/PracticumAI/practicumai.github.io/blob/main/images/icons/practicumai_python.png?raw=true' align='right' width=50>\n",
    "\n",
    "# *Practicum AI Python*: Data Wrangling\n",
    "\n",
    "This exercise adapted from Lipp et al. (2020) <i>The Data Wrangling Workshop</i> from <a href=\"https://www.packtpub.com/product/the-data-wrangling-workshop-second-edition/9781839215001\">Packt Publishers</a> and the <a href=\"https://github.com/swcarpentry/python-novice-gapminder\">Software Carpentries</a>\n",
    "\n",
    "(20 Minutes: Presentation)\n",
    "\n",
    "***\n",
    "\n",
    "<img src='images/universe.png' align='left' width=150 alt='A bunch of planets and stars'> In the previous notebooks, we have focused on Python fundamentals that have hopefully given you a flavor of Python, coding, and working in Jupyter. There is a **lot** more to Python, and we have more to cover, but this transitions to being more focused on the applications of data science and artificial intelligence that will be covered in the rest of the *Practicum AI* curriculum. **We are only introducing a small portion of the Python universe!** Python is used for everything from games and art to AI and scientific discovery. Our goal is not to make you a Python programmer, but it start you learning enough to continue learning what you need to accomplish your goals.\n",
    "\n",
    "In this section, we will start to explore [Pandas](https://pandas.pydata.org/), one of the main data manipulation fraeworks. <img src='images/pandas_logo.png' alt='The Pandas logo' align='right' width=200>\n",
    "\n",
    "The developers of Pandas describe it as:\n",
    "\n",
    " > pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "\n",
    "\n",
    "## 1. Pandas Dataframes\n",
    "\n",
    "Pandas provides one of the most useful data structures for managing data: the dataframe. Pandas dataframes allow fast, flexible, and efficient data manipulation. Dataframes are the natural data structure for tabular data.\n",
    "\n",
    "A [DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) (2 dimensional--rows and columns) is a collection of [Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html) (1 dimensional). The DataFrame is the way Pandas represents a table, and Series is the data-structure Pandas use to represent a column.\n",
    "\n",
    "Pandas is built on top of the [Numpy](http://www.numpy.org/) library, which in practice means that most of the methods defined for Numpy Arrays apply to Pandas Series/DataFrames.\n",
    "\n",
    "What makes Pandas so attractive is the powerful interface to access individual records of the table, proper handling of missing values, and relational-databases operations between DataFrames.\n",
    "\n",
    "## 2. Creating a series\n",
    "\n",
    "We will start with making a Pandas series. Both Numpy and Pandas are usually imported with abbreviated aliases, `np` and `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some standard Python lists, a numpy array and a dictionary\n",
    "\n",
    "labels = ['a', 'b', 'c']\n",
    "my_data = [10,20,30]\n",
    "array_1 = np.array(my_data)\n",
    "d = {'a':10, 'b':20, 'c':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from my_data\n",
    "\n",
    "pd.Series(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from labels\n",
    "\n",
    "pd.Series(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Pandas Dataframes\n",
    "\n",
    "Now that we've seen series, we can look at how these are combined as columns in tables.\n",
    "\n",
    "While we will start with the common name `df` for our dataframe, like any variable name, it helps if it meaningful! Again, there is nothing special about the name `df`, but you will see it used everywhere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=my_data, index=labels, columns=['Data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some random numbers for data. \n",
    "\n",
    "# This makes an array of random integers from 1-10, then reshapes it into a 5x4 matrix\n",
    "data = np.random.randint(1,10, size=20).reshape(5,4)\n",
    "\n",
    "# Make row and colum labels\n",
    "row_labels = ['A', 'B', 'C', 'D', 'E']  # need 5 rows\n",
    "column_headings = ['W', 'X', 'Y', 'Z']  # need 4 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data, index=row_labels,\n",
    "                 columns=column_headings)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Viewing Parts of a Dataframe\n",
    "\n",
    "Dataframes frequently hold lots of data and we want to explore them without getting pages of output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a slightly larger dataframe to work with\n",
    "\n",
    "data = np.random.randint(1,100,100).reshape(25,4)\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=column_headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the 1st 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the last 3 rows (head also takes a number or rows as an optional argument)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the X column (only works if there are no spaces in the column names!)\n",
    "df.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View multiple columns or if there are spaces in names\n",
    "# Note the double square brackets!\n",
    "df[['X', 'Z']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating a Dataframe From a File\n",
    "\n",
    "One of the great things about Pandas is how easy it is to load tabular data from a file into a dataframe. There are functions to load data from csv (comma separated value) files, Excel files, and even directly from files on the web.\n",
    "\n",
    "Here, we'll load a dataset from the `data` folder and look at the `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe with this command if you are running this notebook in Colab:\n",
    "\n",
    "gapminder = pd.read_csv(\"https://raw.githubusercontent.com/PracticumAI/python/main/data/gapminder_gdp_europe.csv\", index_col = 'country')\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #AF1830;border-left-width: 10px;background-color: #fff\"><strong>Warning:</strong> Do not execute the code block below if you are running this notebook in Colab.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe from a local file.\n",
    "\n",
    "gapminder = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Indexing and Slicing\n",
    "\n",
    "To access the value of a particular cell of a DataFrame, we have two options, depending on what information we have. \n",
    "\n",
    "Columns and rows exist in an order, and can be accessed similarly to lists using numeric indices (counting from 0). Columns and rows can also have labeled names (as in the country indices in the `gapmanider` dataframe above).\n",
    "\n",
    "We'll start with two examples. Let's imagine we want to get the value from row 4, column X from a dataframe. First, we need to remember that Python uses 0-based indexing. So, the 4th row is row index 3, and X is column index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a dataframe for the example\n",
    "\n",
    "data = np.random.randint(1,100, size=20).reshape(5,4)\n",
    "\n",
    "# Make row and colum labels\n",
    "row_labels = ['A', 'B', 'C', 'D', 'E']  # need 5 rows\n",
    "column_headings = ['W', 'X', 'Y', 'Z']  # need 4 columns\n",
    "\n",
    "df = pd.DataFrame(data=data, index=row_labels,\n",
    "                 columns=column_headings)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value from for the 4th row, colum X using iloc\n",
    "\n",
    "df.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value from for the 4th row, colum X using loc\n",
    "\n",
    "df.loc['D', 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` and `loc` can oth be useful at different times. Learning to use each will help you as you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Select multiple columns or rows using `DataFrame.loc` and a named slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we discover that **slicing using `loc` is inclusive at both ends**, which differs from **slicing using `iloc`, where slicing indicates everything up to but not including the final index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:3,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Result of slicing can be used in further operations\n",
    "\n",
    "* SLices are most typically used to select portions of data tables, not simply print them\n",
    "* All the statistical operators that work on entire dataframes work the same way on slices.\n",
    "* E.g., calculate max of a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use comparisons to select data based on value\n",
    "\n",
    "* Comparison is applied element by element.\n",
    "* Returns a similarly-shaped dataframe of `True` and `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of data to keep output readable.\n",
    "subset = gapminder.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972']\n",
    "print('Subset of data:\\n', subset)\n",
    "\n",
    "# Which values were greater than 10000 ?\n",
    "print('\\nWhere are values large?\\n', subset > 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating and deleting new rows and columns\n",
    "\n",
    "We can add and remove rows and columns in our dataframes.\n",
    "\n",
    "Let's add a column with the change in per capita GDP from 1962 to 2007 to our `gapminder` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder['gdpChange'] = gapminder['gdpPercap_2007'] - gapminder['gdpPercap_1962']\n",
    "\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **drop** columns. Let's say, we determined that there was something wrong with the 1992 data and we want to get rid of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder.drop('gdpPercap_1992', axis=1)\n",
    "\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happened?? `gdpPercap_1992` is still there!!**\n",
    "\n",
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #E5C250;border-left-width: 10px;background-color: #fff\">\n",
    "    <p><strong>Tip:</strong> Unless you specify <code>inplace=True</code> or assign the dataframe back to itself (or a different variable name) <strong>the <code>drop</code> method does not change the original dataframe!!</strong></p>\n",
    "   </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo above, assigning result to gapminder\n",
    "\n",
    "gapminder = gapminder.drop('gdpPercap_1992', axis=1)\n",
    "\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use inplace=True to drop gdpPercap_1957\n",
    "\n",
    "gapminder.drop('gdpPercap_1957', axis=1, inplace=True)\n",
    "\n",
    "gapminder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Select values or `NaN` using a Boolean mask\n",
    "\n",
    "* A frame full of Booleans is sometimes called a *mask* because of how it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = subset > 10000\n",
    "subset[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the value where the mask is true, and NaN (Not a Number) where it is false.\n",
    "* Useful because NaNs are ignored by operations like max, min, average, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[subset > 10000].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Select-Apply-Combine operations\n",
    "\n",
    "Pandas vectorizing methods and grouping operations are features that provide users much flexibility to analyze their data.\n",
    "\n",
    "For instance, let's say we want to have a clearer view on how the European countries split themselves according to their GDP.\n",
    "\n",
    "1. We may have a glance by splitting the countries in two groups during the years surveyed, those who presented a GDP *higher* than the European average and those with a *lower* GDP.\n",
    "2. We then estimate a *wealthy score* based on the historical (from 1962 to 2007) values, where we account how many times a country has participated in the groups of *lower* or *higher* GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_higher = gapminder.apply(lambda x:x>x.mean())\n",
    "wealth_score = mask_higher.aggregate('sum',axis=1)/len(gapminder.columns)\n",
    "wealth_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for each group in the `wealth_score` table, we sum their (financial) contribution across the years surveyed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder.groupby(wealth_score).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Bonus Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Selection of Individual Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Pandas has been imported into your notebook and the Gapminder GDP data for Europe has been loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('data/gapminder_gdp_europe.csv', index_col = 'country')\n",
    "\n",
    "# Load the dataframe with this command if you are running this notebook in Colab:\n",
    "# df = pandas.read_csv('https://raw.githubusercontent.com/PracticumAI/python/main/data/gapminder_gdp_europe.csv', index_col='country')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an expression to find the Per Capita GDP of Serbia in 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The selection can be done by using the labels for both the row (\"Serbia\") and \n",
    "# the column (\"gdpPercap_2007\"):\n",
    "\n",
    "print(df.loc['Serbia', 'gdpPercap_2007'])\n",
    "\n",
    "# The output is:\n",
    "\n",
    "9786.534714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Extent of Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do the two statements below produce the same output?\n",
    "2. Based on this, what rule governs what is included (or not) in numerical slices and named slices in Pandas?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[0:2, 0:2])\n",
    "print(data.loc['Albania':'Belgium', 'gdpPercap_1952':'gdpPercap_1962'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# No, they do not produce the same output! The output of the first statement is:\n",
    "\n",
    "        gdpPercap_1952  gdpPercap_1957\n",
    "country                                \n",
    "Albania     1601.056136     1942.284244\n",
    "Austria     6137.076492     8842.598030\n",
    "\n",
    "# The second statement gives:\n",
    "\n",
    "        gdpPercap_1952  gdpPercap_1957  gdpPercap_1962\n",
    "country                                                \n",
    "Albania     1601.056136     1942.284244     2312.888958\n",
    "Austria     6137.076492     8842.598030    10750.721110\n",
    "Belgium     8343.105127     9714.960623    10991.206760\n",
    "\n",
    "# Clearly, the second statement produces an additional column and an additional \n",
    "# row compared to the first statement.  What conclusion can we draw? We see that \n",
    "# a numerical slice, 0:2, omits the final index (i.e. index 2) in the range \n",
    "# provided, while a named slice, gdpPercap_1952 : gdpPercap_1962 , includes \n",
    "# the final element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Reconstructing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what each line in the following short program does: what is in first, second, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explain what each line in the following short program does: what is in first, second, etc.?\n",
    "\n",
    "first = pandas.read_csv('data/gapminder_all.csv', index_col = 'country')\n",
    "\n",
    "# Load the dataframe with this command if you are running this notebook in Colab:\n",
    "# first = pandas.read_csv('https://raw.githubusercontent.com/PracticumAI/python/main/data/gapminder_all.csv', index_col='country')\n",
    "\n",
    "second = first[first['continent'] == 'Americas']\n",
    "third  = second.drop('Puerto Rico')\n",
    "fourth = third.drop('continent', axis = 1)\n",
    "\n",
    "fourth.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's go through this piece of code line by line.\n",
    "\n",
    "first = pandas.read_csv('data/gapminder_all.csv', index_col='country')\n",
    "\n",
    "# This line loads the dataset containing the GDP data from all countries into a \n",
    "# dataframe called `first`. The `index_col='country'` parameter selects which \n",
    "# column to use as the row labels in the dataframe.  \n",
    "\n",
    "second = first[first['continent'] == 'Americas']\n",
    "\n",
    "# This line makes a selection: only those rows of `first` for which the \n",
    "# 'continent' column matches 'Americas' are extracted. Notice how the Boolean \n",
    "# expression inside the brackets, `first['continent'] == 'Americas'`, is used \n",
    "# to select only those rows where the expression is true. Try printing this \n",
    "# expression! Can you print also its individual True/False elements? (hint: \n",
    "# first assign the expression to a variable) \n",
    "\n",
    "third = second.drop('Puerto Rico')\n",
    "\n",
    "# As the syntax suggests, this line drops the row from `second` where the label \n",
    "# is 'Puerto Rico'. The resulting dataframe `third` has one row less than the \n",
    "# original dataframe `second`.\n",
    "\n",
    "fourth = third.drop('continent', axis = 1)\n",
    "\n",
    "# Again we apply the drop function, but in this case we are dropping not a row \n",
    "# but a whole column. To accomplish this, we need to specify also the `axis` \n",
    "# parameter (we want to drop the second column which has index 1).\n",
    "\n",
    "fourth.to_csv('result.csv')\n",
    "\n",
    "# The final step is to write the data that we have been working on to a csv \n",
    "# file. Pandas makes this easy with the `to_csv()` function. The only required \n",
    "# argument to the function is the filename. Note that the file will be written \n",
    "# in the directory from which you started the Jupyter or Python session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Selecting Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain in simple terms what idxmin and idxmax do in the short program below. When would you use these methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_europe.csv', index_col = 'country')\n",
    "\n",
    "# Load the dataframe with this command if you are running this notebook in Colab:\n",
    "# df = pandas.read_csv('https://raw.githubusercontent.com/PracticumAI/python/main/data/gapminder_gdp_europe.csv', index_col='country')\n",
    "\n",
    "print(data.idxmin())\n",
    "print(data.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For each column in `data`, `idxmin` will return the index value corresponding \n",
    "# to each column's minimum; `idxmax` will do accordingly the same for each \n",
    "# column's maximum value.\n",
    "\n",
    "# You can use these functions whenever you want to get the row index of the \n",
    "# minimum/maximum value and not the actual minimum/maximum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Practice with Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Pandas has been imported and the Gapminder GDP data for Europe has been loaded. Write an expression to select each of the following:\n",
    "\n",
    "1. GDP per capita for all countries in 1982.\n",
    "2. GDP per capita for Denmark for all years.\n",
    "3. GDP per capita for all countries for years after 1985.\n",
    "4. GDP per capita for each country in 2007 as a multiple of GDP per capita for that country in 1952.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. -------------------------------------\n",
    "data['gdpPercap_1982']\n",
    "\n",
    "# 2. -------------------------------------\n",
    "data.loc['Denmark',:]\n",
    "\n",
    "# 3. -------------------------------------\n",
    "data.loc[:,'gdpPercap_1985':]\n",
    "\n",
    "# Pandas is smart enough to recognize the number at the end of the column label \n",
    "# and does not give you an error, although no column named `gdpPercap_1985` \n",
    "# actually exists. This is useful if new columns are added to the CSV file later.\n",
    "\n",
    "# 4. -------------------------------------\n",
    "data['gdpPercap_2007']/data['gdpPercap_1952'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: Using `dir` function to see available methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python includes a `dir` function that can be used to display all of the available methods (functions) that are built into a data object.  As an example, the  functions available for a [list data type](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potatoes = [\"Russet\", \"Norkota\", \"Yukon Gold\", \"Pontiac\"]\n",
    "dir(potatoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['__add__',\n",
    "...\n",
    "'__subclasshook__',\n",
    "'append',\n",
    "'clear',\n",
    "'copy',\n",
    "'count',\n",
    "'extend',\n",
    "'index',\n",
    "'insert',\n",
    "'pop',\n",
    "'remove',\n",
    "'reverse',\n",
    "'sort']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The double underscore functions can be ignored for now; functions that are not surrounded by double underscores are the *public interface* of the [list type](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists). So, if you want to sort the list of potatoes, according to `dir` you should try,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potatoes.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume Pandas has been imported and the Gapminder GDP data for Europe has been loaded as `data`.  Then, use `dir` to find the function that prints out the median per-capita GDP across all European countries for each year that information is available.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Click on the '...' below to show the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Among many choices, dir lists the `median()` function as a possibility.  Thus,\n",
    "\n",
    "data.median()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.8",
   "language": "python",
   "name": "python3-3.8-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
